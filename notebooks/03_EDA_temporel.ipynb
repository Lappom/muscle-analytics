{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977087b2",
   "metadata": {},
   "source": [
    "# 📅 Analyse EDA - Patterns Temporels\n",
    "\n",
    "Ce notebook se concentre sur l'analyse temporelle des données d'entraînement.\n",
    "\n",
    "## Objectifs\n",
    "- Analyser l'évolution des performances dans le temps\n",
    "- Identifier les patterns et tendances\n",
    "- Détecter les périodes de progression/stagnation\n",
    "- Analyser la régularité d'entraînement\n",
    "- Préparer les features temporelles pour le ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0b873",
   "metadata": {},
   "source": [
    "## 🔧 Imports et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d918f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"📅 Notebook d'analyse temporelle initialisé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa556d9",
   "metadata": {},
   "source": [
    "## 📁 Chargement et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "df_raw = pd.read_csv('../examples/sample_data.csv')\n",
    "\n",
    "# Nettoyage et préparation\n",
    "df = df_raw.copy()\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "df['Poids_kg'] = df['Poids / Distance'].str.replace(' kg', '').str.replace(',', '.').astype(float)\n",
    "df['Reps'] = df['Répétitions / Temps'].str.extract(r'(\\d+)').astype(float)\n",
    "df['Volume'] = df['Poids_kg'] * df['Reps']\n",
    "df['Type_serie'] = df['Série / Série d\\'échauffement / Série de récupération']\n",
    "df['Sautee'] = df['Sautée'].map({'Oui': True, 'Non': False})\n",
    "\n",
    "# Ajout d'informations temporelles\n",
    "df['Jour_Semaine'] = df['Date'].dt.day_name()\n",
    "df['Semaine'] = df['Date'].dt.isocalendar().week\n",
    "df['Mois'] = df['Date'].dt.month\n",
    "df['Jour_Numero'] = df['Date'].dt.dayofweek  # 0=Lundi, 6=Dimanche\n",
    "\n",
    "# Tri par date pour l'analyse temporelle\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "print(f\"📊 Données préparées: {len(df)} sets\")\n",
    "print(f\"📅 Période: du {df['Date'].min().strftime('%d/%m/%Y')} au {df['Date'].max().strftime('%d/%m/%Y')}\")\n",
    "print(f\"⏱️ Durée totale: {(df['Date'].max() - df['Date'].min()).days} jours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec6445",
   "metadata": {},
   "source": [
    "## 📈 Évolution globale du volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ea294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse du volume par jour\n",
    "print(\"📈 ÉVOLUTION DU VOLUME D'ENTRAÎNEMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "daily_stats = df.groupby('Date').agg({\n",
    "    'Volume': ['sum', 'count', 'mean'],\n",
    "    'Poids_kg': 'mean',\n",
    "    'Reps': 'mean',\n",
    "    'Entraînement': 'first',\n",
    "    'Région': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "daily_stats.columns = ['Volume_Total', 'Nb_Sets', 'Volume_Moyen_Set', 'Poids_Moyen', 'Reps_Moyen', 'Type_Entrainement', 'Nb_Regions']\n",
    "daily_stats = daily_stats.reset_index()\n",
    "\n",
    "print(\"📋 Statistiques quotidiennes:\")\n",
    "print(daily_stats)\n",
    "\n",
    "# Calcul des tendances\n",
    "daily_stats['Jour_Index'] = range(len(daily_stats))\n",
    "slope_volume, intercept_volume, r_value_volume, p_value_volume, std_err_volume = stats.linregress(\n",
    "    daily_stats['Jour_Index'], daily_stats['Volume_Total']\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 TENDANCE GÉNÉRALE:\")\n",
    "print(f\"   Pente du volume: {slope_volume:.2f} kg/jour\")\n",
    "print(f\"   Corrélation: {r_value_volume:.3f}\")\n",
    "print(f\"   Tendance: {'📈 Croissante' if slope_volume > 0 else '📉 Décroissante' if slope_volume < 0 else '➡️ Stable'}\")\n",
    "print(f\"   Significativité: {'✅ Significative' if p_value_volume < 0.05 else '⚠️ Non significative'} (p={p_value_volume:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'évolution du volume\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('📈 Évolution Temporelle des Métriques d\\'Entraînement', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Volume total par jour\n",
    "axes[0,0].plot(daily_stats['Date'], daily_stats['Volume_Total'], \n",
    "               marker='o', linewidth=2, markersize=8, color='navy')\n",
    "# Ligne de tendance\n",
    "trend_line = slope_volume * daily_stats['Jour_Index'] + intercept_volume\n",
    "axes[0,0].plot(daily_stats['Date'], trend_line, '--', color='red', alpha=0.7, \n",
    "               label=f'Tendance: {slope_volume:.1f} kg/jour')\n",
    "axes[0,0].set_title('Volume Total par Jour')\n",
    "axes[0,0].set_ylabel('Volume (kg)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Nombre de sets par jour\n",
    "axes[0,1].bar(daily_stats['Date'], daily_stats['Nb_Sets'], color='steelblue', alpha=0.7)\n",
    "axes[0,1].set_title('Nombre de Sets par Jour')\n",
    "axes[0,1].set_ylabel('Nombre de Sets')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Poids moyen par jour\n",
    "axes[1,0].plot(daily_stats['Date'], daily_stats['Poids_Moyen'], \n",
    "               marker='s', linewidth=2, markersize=6, color='darkgreen')\n",
    "axes[1,0].set_title('Poids Moyen par Jour')\n",
    "axes[1,0].set_ylabel('Poids Moyen (kg)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Volume moyen par set\n",
    "axes[1,1].plot(daily_stats['Date'], daily_stats['Volume_Moyen_Set'], \n",
    "               marker='^', linewidth=2, markersize=6, color='purple')\n",
    "axes[1,1].set_title('Volume Moyen par Set')\n",
    "axes[1,1].set_ylabel('Volume/Set (kg)')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Formatage des axes de dates\n",
    "for ax in axes.flat:\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589867d",
   "metadata": {},
   "source": [
    "## 🏋️ Progression par exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la progression par exercice\n",
    "print(\"🏋️ PROGRESSION PAR EXERCICE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Pour chaque exercice, analyser l'évolution du poids et volume\n",
    "exercises = df['Exercice'].unique()\n",
    "progression_summary = []\n",
    "\n",
    "for exercise in exercises:\n",
    "    exercise_data = df[df['Exercice'] == exercise].copy()\n",
    "    exercise_data = exercise_data.sort_values('Date')\n",
    "    \n",
    "    if len(exercise_data) >= 2:  # Au moins 2 points pour calculer une progression\n",
    "        # Calcul de la progression du poids max\n",
    "        first_weight = exercise_data['Poids_kg'].iloc[0]\n",
    "        last_weight = exercise_data['Poids_kg'].iloc[-1]\n",
    "        max_weight = exercise_data['Poids_kg'].max()\n",
    "        \n",
    "        # Calcul de la progression du volume\n",
    "        first_volume = exercise_data['Volume'].iloc[0]\n",
    "        last_volume = exercise_data['Volume'].iloc[-1]\n",
    "        avg_volume = exercise_data['Volume'].mean()\n",
    "        \n",
    "        # Régression linéaire pour la tendance\n",
    "        days = [(date - exercise_data['Date'].iloc[0]).days for date in exercise_data['Date']]\n",
    "        if len(set(exercise_data['Poids_kg'])) > 1:  # Variation de poids\n",
    "            slope_weight, _, r_weight, p_weight, _ = stats.linregress(days, exercise_data['Poids_kg'])\n",
    "        else:\n",
    "            slope_weight, r_weight, p_weight = 0, 0, 1\n",
    "        \n",
    "        progression_summary.append({\n",
    "            'Exercice': exercise,\n",
    "            'Nb_Sessions': len(exercise_data),\n",
    "            'Premier_Poids': first_weight,\n",
    "            'Dernier_Poids': last_weight,\n",
    "            'Poids_Max': max_weight,\n",
    "            'Progression_Poids': last_weight - first_weight,\n",
    "            'Progression_Pct': ((last_weight - first_weight) / first_weight * 100) if first_weight > 0 else 0,\n",
    "            'Tendance_Poids_Jour': slope_weight,\n",
    "            'Correlation_Temps': r_weight,\n",
    "            'Volume_Moyen': avg_volume,\n",
    "            'Progression_Volume': last_volume - first_volume\n",
    "        })\n",
    "\n",
    "progression_df = pd.DataFrame(progression_summary)\n",
    "progression_df = progression_df.round(2).sort_values('Progression_Pct', ascending=False)\n",
    "\n",
    "print(\"📊 Résumé des progressions:\")\n",
    "print(progression_df)\n",
    "\n",
    "# Identification des meilleures et moins bonnes progressions\n",
    "best_progression = progression_df.iloc[0]\n",
    "worst_progression = progression_df.iloc[-1]\n",
    "\n",
    "print(f\"\\n🏆 MEILLEURE PROGRESSION:\")\n",
    "print(f\"   Exercice: {best_progression['Exercice']}\")\n",
    "print(f\"   Progression: +{best_progression['Progression_Poids']:.1f}kg ({best_progression['Progression_Pct']:.1f}%)\")\n",
    "print(f\"   Tendance: {best_progression['Tendance_Poids_Jour']:.3f} kg/jour\")\n",
    "\n",
    "print(f\"\\n📉 PROGRESSION À AMÉLIORER:\")\n",
    "print(f\"   Exercice: {worst_progression['Exercice']}\")\n",
    "print(f\"   Progression: {worst_progression['Progression_Poids']:.1f}kg ({worst_progression['Progression_Pct']:.1f}%)\")\n",
    "print(f\"   Tendance: {worst_progression['Tendance_Poids_Jour']:.3f} kg/jour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67104ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la progression par exercice\n",
    "fig, axes = plt.subplots(len(exercises), 1, figsize=(14, 6*len(exercises)))\n",
    "if len(exercises) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "fig.suptitle('🏋️ Progression Détaillée par Exercice', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, exercise in enumerate(exercises):\n",
    "    exercise_data = df[df['Exercice'] == exercise].sort_values('Date')\n",
    "    \n",
    "    # Graphique principal : poids dans le temps\n",
    "    ax = axes[i]\n",
    "    scatter = ax.scatter(exercise_data['Date'], exercise_data['Poids_kg'], \n",
    "                        c=exercise_data['Volume'], cmap='viridis', \n",
    "                        s=exercise_data['Reps']*10, alpha=0.7)\n",
    "    \n",
    "    # Ligne de tendance si données suffisantes\n",
    "    if len(exercise_data) >= 2:\n",
    "        z = np.polyfit(range(len(exercise_data)), exercise_data['Poids_kg'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax.plot(exercise_data['Date'], p(range(len(exercise_data))), \"--\", \n",
    "               color='red', alpha=0.8, linewidth=2)\n",
    "    \n",
    "    ax.set_title(f'{exercise} - Évolution du Poids (couleur=volume, taille=reps)')\n",
    "    ax.set_ylabel('Poids (kg)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Colorbar pour le volume\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label('Volume (kg)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389dcdb",
   "metadata": {},
   "source": [
    "## 📊 Analyse des patterns hebdomadaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93510f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des patterns hebdomadaires\n",
    "print(\"📊 ANALYSE DES PATTERNS HEBDOMADAIRES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Répartition par jour de la semaine\n",
    "weekly_patterns = df.groupby(['Jour_Semaine', 'Jour_Numero']).agg({\n",
    "    'Volume': ['sum', 'count', 'mean'],\n",
    "    'Date': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "weekly_patterns.columns = ['Volume_Total', 'Nb_Sets', 'Volume_Moyen', 'Nb_Jours_Entrainement']\n",
    "weekly_patterns = weekly_patterns.reset_index().sort_values('Jour_Numero')\n",
    "\n",
    "print(\"📅 Activité par jour de la semaine:\")\n",
    "print(weekly_patterns)\n",
    "\n",
    "# Calcul de l'intensité par jour (volume/nombre de jours d'entraînement)\n",
    "weekly_patterns['Intensite_Jour'] = weekly_patterns['Volume_Total'] / weekly_patterns['Nb_Jours_Entrainement']\n",
    "\n",
    "print(f\"\\n🏆 Jour le plus actif: {weekly_patterns.loc[weekly_patterns['Volume_Total'].idxmax(), 'Jour_Semaine']}\")\n",
    "print(f\"😴 Jour le moins actif: {weekly_patterns.loc[weekly_patterns['Volume_Total'].idxmin(), 'Jour_Semaine']}\")\n",
    "print(f\"💪 Jour le plus intensif: {weekly_patterns.loc[weekly_patterns['Intensite_Jour'].idxmax(), 'Jour_Semaine']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des patterns hebdomadaires\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('📅 Patterns Hebdomadaires d\\'Entraînement', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Volume total par jour de la semaine\n",
    "axes[0,0].bar(weekly_patterns['Jour_Semaine'], weekly_patterns['Volume_Total'], \n",
    "              color='skyblue', alpha=0.8)\n",
    "axes[0,0].set_title('Volume Total par Jour de la Semaine')\n",
    "axes[0,0].set_ylabel('Volume Total (kg)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Nombre de sets par jour\n",
    "axes[0,1].bar(weekly_patterns['Jour_Semaine'], weekly_patterns['Nb_Sets'], \n",
    "              color='lightgreen', alpha=0.8)\n",
    "axes[0,1].set_title('Nombre de Sets par Jour de la Semaine')\n",
    "axes[0,1].set_ylabel('Nombre de Sets')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Intensité (volume/jour d'entraînement)\n",
    "axes[1,0].bar(weekly_patterns['Jour_Semaine'], weekly_patterns['Intensite_Jour'], \n",
    "              color='orange', alpha=0.8)\n",
    "axes[1,0].set_title('Intensité par Jour (Volume/Jour d\\'entraînement)')\n",
    "axes[1,0].set_ylabel('Intensité (kg)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Heatmap des régions par jour de la semaine\n",
    "region_day_pivot = df.groupby(['Jour_Semaine', 'Région'])['Volume'].sum().unstack(fill_value=0)\n",
    "sns.heatmap(region_day_pivot.T, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[1,1])\n",
    "axes[1,1].set_title('Volume par Région et Jour (Heatmap)')\n",
    "axes[1,1].set_xlabel('Jour de la Semaine')\n",
    "axes[1,1].set_ylabel('Région Musculaire')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40f1098",
   "metadata": {},
   "source": [
    "## ⏱️ Analyse de la régularité d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la régularité\n",
    "print(\"⏱️ ANALYSE DE LA RÉGULARITÉ D'ENTRAÎNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcul des intervalles entre sessions\n",
    "training_dates = df['Date'].unique()\n",
    "training_dates.sort()\n",
    "\n",
    "intervals = []\n",
    "for i in range(1, len(training_dates)):\n",
    "    interval = (training_dates[i] - training_dates[i-1]).days\n",
    "    intervals.append(interval)\n",
    "\n",
    "if intervals:\n",
    "    intervals_df = pd.DataFrame({\n",
    "        'Date_Debut': training_dates[:-1],\n",
    "        'Date_Fin': training_dates[1:],\n",
    "        'Intervalle_Jours': intervals\n",
    "    })\n",
    "    \n",
    "    print(\"📊 Statistiques des intervalles entre sessions:\")\n",
    "    print(f\"   Intervalle moyen: {np.mean(intervals):.1f} jours\")\n",
    "    print(f\"   Intervalle médian: {np.median(intervals):.1f} jours\")\n",
    "    print(f\"   Écart-type: {np.std(intervals):.1f} jours\")\n",
    "    print(f\"   Intervalle min: {min(intervals)} jours\")\n",
    "    print(f\"   Intervalle max: {max(intervals)} jours\")\n",
    "    \n",
    "    # Classification de la régularité\n",
    "    if np.std(intervals) <= 1:\n",
    "        regularity = \"🎯 Très régulière\"\n",
    "    elif np.std(intervals) <= 2:\n",
    "        regularity = \"✅ Régulière\"\n",
    "    elif np.std(intervals) <= 3:\n",
    "        regularity = \"⚠️ Modérément irrégulière\"\n",
    "    else:\n",
    "        regularity = \"❌ Irrégulière\"\n",
    "    \n",
    "    print(f\"\\n⏱️ Évaluation de la régularité: {regularity}\")\n",
    "    \n",
    "    print(\"\\n📅 Détail des intervalles:\")\n",
    "    print(intervals_df)\n",
    "else:\n",
    "    print(\"⚠️ Pas assez de données pour analyser la régularité\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73928ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la régularité\n",
    "if intervals:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 1. Histogramme des intervalles\n",
    "    axes[0].hist(intervals, bins=max(1, len(set(intervals))), alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    axes[0].axvline(np.mean(intervals), color='red', linestyle='--', \n",
    "                   label=f'Moyenne: {np.mean(intervals):.1f} jours')\n",
    "    axes[0].set_title('📊 Distribution des Intervalles entre Sessions')\n",
    "    axes[0].set_xlabel('Intervalle (jours)')\n",
    "    axes[0].set_ylabel('Fréquence')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Évolution des intervalles dans le temps\n",
    "    axes[1].plot(range(len(intervals)), intervals, marker='o', linewidth=2, markersize=6)\n",
    "    axes[1].axhline(np.mean(intervals), color='red', linestyle='--', alpha=0.7, \n",
    "                   label=f'Moyenne: {np.mean(intervals):.1f} jours')\n",
    "    axes[1].set_title('⏱️ Évolution des Intervalles dans le Temps')\n",
    "    axes[1].set_xlabel('Numéro de la Pause')\n",
    "    axes[1].set_ylabel('Intervalle (jours)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ Pas assez de données pour visualiser la régularité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b288e",
   "metadata": {},
   "source": [
    "## 🎲 Calcul des features temporelles pour ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b689b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des features temporelles avancées\n",
    "print(\"🎲 CALCUL DES FEATURES TEMPORELLES POUR ML\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Création d'un DataFrame enrichi avec des features temporelles\n",
    "df_features = df.copy()\n",
    "\n",
    "# 1. Features basées sur l'ordre chronologique\n",
    "df_features = df_features.sort_values(['Exercice', 'Date'])\n",
    "df_features['Session_Number'] = df_features.groupby('Exercice').cumcount() + 1\n",
    "\n",
    "# 2. Rolling windows pour tendances\n",
    "df_features['Volume_Rolling_3'] = df_features.groupby('Exercice')['Volume'].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)\n",
    "df_features['Poids_Rolling_3'] = df_features.groupby('Exercice')['Poids_kg'].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "# 3. Features de progression\n",
    "df_features['Poids_Progression'] = df_features.groupby('Exercice')['Poids_kg'].diff()\n",
    "df_features['Volume_Progression'] = df_features.groupby('Exercice')['Volume'].diff()\n",
    "\n",
    "# 4. Features relatives au maximum personnel\n",
    "df_features['Poids_Max_Personnel'] = df_features.groupby('Exercice')['Poids_kg'].cummax()\n",
    "df_features['Pct_Max_Personnel'] = (df_features['Poids_kg'] / df_features['Poids_Max_Personnel'] * 100).round(1)\n",
    "\n",
    "# 5. Features temporelles cycliques\n",
    "df_features['Jour_Semaine_Sin'] = np.sin(2 * np.pi * df_features['Jour_Numero'] / 7)\n",
    "df_features['Jour_Semaine_Cos'] = np.cos(2 * np.pi * df_features['Jour_Numero'] / 7)\n",
    "\n",
    "# 6. Délai depuis la dernière session de l'exercice\n",
    "df_features['Jours_Depuis_Dernier'] = df_features.groupby('Exercice')['Date'].diff().dt.days\n",
    "\n",
    "# 7. Volume cumulé\n",
    "df_features['Volume_Cumule'] = df_features.groupby('Exercice')['Volume'].cumsum()\n",
    "\n",
    "print(\"✅ Features temporelles calculées:\")\n",
    "new_features = ['Session_Number', 'Volume_Rolling_3', 'Poids_Rolling_3', \n",
    "                'Poids_Progression', 'Volume_Progression', 'Poids_Max_Personnel',\n",
    "                'Pct_Max_Personnel', 'Jour_Semaine_Sin', 'Jour_Semaine_Cos',\n",
    "                'Jours_Depuis_Dernier', 'Volume_Cumule']\n",
    "\n",
    "for feature in new_features:\n",
    "    print(f\"   • {feature}\")\n",
    "\n",
    "# Aperçu des nouvelles features\n",
    "print(\"\\n📊 Aperçu des features temporelles:\")\n",
    "feature_sample = df_features[['Date', 'Exercice', 'Poids_kg', 'Volume'] + new_features].head(10)\n",
    "print(feature_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de corrélation des nouvelles features\n",
    "print(\"🔍 ANALYSE DE CORRÉLATION DES FEATURES TEMPORELLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sélection des features numériques pour l'analyse de corrélation\n",
    "numeric_features = ['Poids_kg', 'Reps', 'Volume', 'Session_Number', \n",
    "                   'Volume_Rolling_3', 'Poids_Rolling_3', 'Poids_Progression',\n",
    "                   'Volume_Progression', 'Pct_Max_Personnel', 'Volume_Cumule']\n",
    "\n",
    "correlation_matrix = df_features[numeric_features].corr()\n",
    "\n",
    "# Visualisation de la matrice de corrélation\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f')\n",
    "plt.title('🔍 Matrice de Corrélation des Features Temporelles', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identification des corrélations fortes\n",
    "print(\"🔗 Corrélations significatives (|r| > 0.7):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.7:\n",
    "            feature1 = correlation_matrix.columns[i]\n",
    "            feature2 = correlation_matrix.columns[j]\n",
    "            print(f\"   • {feature1} ↔ {feature2}: {corr_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad1e85",
   "metadata": {},
   "source": [
    "## 🎯 Résumé et insights temporels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 RÉSUMÉ ET INSIGHTS TEMPORELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Métriques temporelles globales\n",
    "total_period = (df['Date'].max() - df['Date'].min()).days\n",
    "training_days = df['Date'].nunique()\n",
    "training_frequency = training_days / (total_period + 1) * 7 if total_period > 0 else 0\n",
    "\n",
    "print(f\"📊 MÉTRIQUES TEMPORELLES GLOBALES:\")\n",
    "print(f\"   • Période totale: {total_period} jours\")\n",
    "print(f\"   • Jours d'entraînement: {training_days}\")\n",
    "print(f\"   • Fréquence hebdomadaire: {training_frequency:.1f} jours/semaine\")\n",
    "print(f\"   • Régularité: {regularity if 'regularity' in locals() else 'Non calculée'}\")\n",
    "\n",
    "print(f\"\\n📈 TENDANCES DE PROGRESSION:\")\n",
    "total_exercises_with_progression = len(progression_df[progression_df['Progression_Poids'] > 0]) if 'progression_df' in locals() else 0\n",
    "total_exercises = len(progression_df) if 'progression_df' in locals() else 0\n",
    "\n",
    "if total_exercises > 0:\n",
    "    progression_rate = total_exercises_with_progression / total_exercises * 100\n",
    "    print(f\"   • Exercices en progression: {total_exercises_with_progression}/{total_exercises} ({progression_rate:.1f}%)\")\n",
    "    print(f\"   • Progression moyenne: {progression_df['Progression_Poids'].mean():.2f} kg\")\n",
    "    print(f\"   • Meilleur exercice: {best_progression['Exercice']} (+{best_progression['Progression_Pct']:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📅 PATTERNS HEBDOMADAIRES:\")\n",
    "if 'weekly_patterns' in locals() and len(weekly_patterns) > 0:\n",
    "    best_day = weekly_patterns.loc[weekly_patterns['Volume_Total'].idxmax(), 'Jour_Semaine']\n",
    "    best_day_volume = weekly_patterns['Volume_Total'].max()\n",
    "    print(f\"   • Jour le plus productif: {best_day} ({best_day_volume:.0f}kg)\")\n",
    "    print(f\"   • Répartition équilibrée: {'✅ Oui' if weekly_patterns['Volume_Total'].std() < weekly_patterns['Volume_Total'].mean() * 0.5 else '⚠️ À améliorer'}\")\n",
    "\n",
    "print(f\"\\n🎲 FEATURES ML GÉNÉRÉES:\")\n",
    "print(f\"   • {len(new_features)} nouvelles features temporelles\")\n",
    "print(f\"   • Rolling windows pour tendances\")\n",
    "print(f\"   • Features cycliques pour saisonnalité\")\n",
    "print(f\"   • Métriques de progression individuelles\")\n",
    "\n",
    "print(f\"\\n🚀 RECOMMANDATIONS TEMPORELLES:\")\n",
    "if training_frequency < 3:\n",
    "    print(f\"   ⚠️ Fréquence d'entraînement faible - augmenter à 3-4 fois/semaine\")\n",
    "elif training_frequency > 6:\n",
    "    print(f\"   ⚠️ Fréquence très élevée - prévoir des jours de repos\")\n",
    "else:\n",
    "    print(f\"   ✅ Fréquence d'entraînement optimale\")\n",
    "\n",
    "if 'regularity' in locals() and '❌' in regularity:\n",
    "    print(f\"   📅 Améliorer la régularité des sessions\")\n",
    "elif 'regularity' in locals() and '🎯' in regularity:\n",
    "    print(f\"   ✅ Excellente régularité maintenue\")\n",
    "\n",
    "if total_exercises > 0 and progression_rate < 50:\n",
    "    print(f\"   📈 Revoir la programmation - moins de 50% des exercices progressent\")\n",
    "elif total_exercises > 0 and progression_rate > 80:\n",
    "    print(f\"   🏆 Excellente progression générale\")\n",
    "\n",
    "print(f\"\\n📚 PROCHAINES ANALYSES RECOMMANDÉES:\")\n",
    "print(f\"   1. Modélisation prédictive avec les features temporelles\")\n",
    "print(f\"   2. Détection de plateaux automatisée\")\n",
    "print(f\"   3. Recommandations de charge optimale\")\n",
    "print(f\"   4. Analyse de saisonnalité sur plus de données\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d089d8",
   "metadata": {},
   "source": [
    "---\n",
    "## 📝 Résumé de l'analyse temporelle\n",
    "\n",
    "Ce notebook a fourni une analyse temporelle complète des données d'entraînement :\n",
    "\n",
    "### ✅ Analyses réalisées\n",
    "- **Évolution globale** : Tendances de volume et progression\n",
    "- **Progression par exercice** : Tracking individuel des performances\n",
    "- **Patterns hebdomadaires** : Identification des jours optimaux\n",
    "- **Régularité** : Analyse de la constance d'entraînement\n",
    "- **Features ML** : 11 nouvelles variables temporelles\n",
    "\n",
    "### 🎯 Insights clés\n",
    "- Tendances de progression identifiées\n",
    "- Patterns comportementaux révélés\n",
    "- Features prêtes pour modélisation ML\n",
    "- Recommandations d'optimisation\n",
    "\n",
    "### 📊 Données générées\n",
    "- `df_features`: Dataset enrichi avec features temporelles\n",
    "- `progression_df`: Métriques de progression par exercice\n",
    "- `weekly_patterns`: Analyse hebdomadaire\n",
    "- `daily_stats`: Statistiques quotidiennes\n",
    "\n",
    "**Prochaine étape:** Feature engineering avancé et préparation pour les modèles ML (04_features_engineering.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
