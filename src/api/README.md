# üöÄ API Muscle-Analytics

API REST compl√®te pour l'analyse d'entra√Ænements de musculation, d√©velopp√©e avec FastAPI.

## üìñ Vue d'ensemble

Cette API expose toutes les fonctionnalit√©s d'analyse d√©velopp√©es dans la Phase 2 :
- **Donn√©es de base** : Sessions, sets, exercices
- **Analytics de volume** : Calculs de volume par exercice, session, p√©riode
- **Analytics de 1RM** : Estimations de force maximale avec 4 formules
- **Analytics de progression** : Tendances, d√©tection de plateaux
- **Dashboard** : Vue d'ensemble avec m√©triques cl√©s

## üèóÔ∏è Architecture

```
src/api/
‚îú‚îÄ‚îÄ main.py         # Application FastAPI principale + endpoints
‚îú‚îÄ‚îÄ models.py       # Mod√®les Pydantic pour requ√™tes/r√©ponses
‚îî‚îÄ‚îÄ services.py     # Services pour base de donn√©es et analytics
```

## üöÄ D√©marrage rapide

### 1. Pr√©requis
- Base de donn√©es PostgreSQL en cours d'ex√©cution
- Python avec les d√©pendances install√©es

### 2. D√©marrage de l'API
```bash
# M√©thode recommand√©e
python run_api.py --port 8000 --host localhost

# Ou directement avec uvicorn
python -m uvicorn src.api.main:app --host localhost --port 8000 --reload
```

### 3. Acc√®s √† la documentation
- **API Documentation** : http://localhost:8000/docs
- **Alternative Redoc** : http://localhost:8000/redoc
- **OpenAPI Schema** : http://localhost:8000/openapi.json

## üìä Endpoints disponibles

### üè† Endpoints de base
| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/` | GET | Informations g√©n√©rales et endpoints disponibles |
| `/health` | GET | V√©rification de sant√© de l'API |
| `/status` | GET | Statut d√©taill√© (API + base de donn√©es) |

### üìù Donn√©es d'entra√Ænement
| Endpoint | M√©thode | Description | Param√®tres |
|----------|---------|-------------|------------|
| `/sessions` | GET | Liste des sessions | `start_date`, `end_date` |
| `/sessions/{id}` | GET | D√©tails d'une session avec sets | - |
| `/sets` | GET | Liste des sets | `session_id`, `exercise`, `start_date`, `end_date` |
| `/exercises` | GET | Catalogue des exercices | - |
| `/exercises/practiced` | GET | Liste des exercices pratiqu√©s | - |

### üìà Analytics
| Endpoint | M√©thode | Description | Param√®tres |
|----------|---------|-------------|------------|
| `/analytics/volume` | GET | Analytics de volume | `exercise`, `start_date`, `end_date` |
| `/analytics/one-rm` | GET | Analytics de 1RM | `exercise`, `start_date`, `end_date` |
| `/analytics/progression` | GET | Analytics de progression | `exercise`, `start_date`, `end_date` |
| `/analytics/exercise/{name}` | GET | Analytics compl√®tes pour un exercice | `start_date`, `end_date` |
| `/analytics/dashboard` | GET | Donn√©es du dashboard principal | - |

## üîß Exemples d'utilisation

### R√©cup√©rer toutes les sessions
```bash
curl http://localhost:8000/sessions
```

### Sessions de la derni√®re semaine
```bash
curl "http://localhost:8000/sessions?start_date=2025-08-23&end_date=2025-08-30"
```

### Analytics de volume pour un exercice
```bash
curl "http://localhost:8000/analytics/volume?exercise=D√©velopp√© couch√©"
```

### Dashboard complet
```bash
curl http://localhost:8000/analytics/dashboard
```

## üìã Format des r√©ponses

### Session
```json
{
  "id": 1,
  "date": "2025-08-30",
  "start_time": "10:00",
  "training_name": "Push A",
  "notes": "Bonne s√©ance",
  "created_at": "2025-08-30T10:00:00"
}
```

### Set
```json
{
  "id": 1,
  "session_id": 1,
  "exercise": "D√©velopp√© couch√©",
  "series_type": "principale",
  "reps": 10,
  "weight_kg": 80.0,
  "notes": "",
  "skipped": false,
  "created_at": "2025-08-30T10:05:00"
}
```

### Analytics de Volume
```json
{
  "exercise": "D√©velopp√© couch√©",
  "total_volume": 1650.0,
  "avg_volume_per_set": 82.5,
  "avg_volume_per_session": 330.0,
  "weekly_volume": 660.0,
  "monthly_volume": 1650.0
}
```

### Analytics de 1RM
```json
{
  "exercise": "D√©velopp√© couch√©",
  "best_1rm_epley": 110.0,
  "best_1rm_brzycki": 108.0,
  "best_1rm_lander": 107.0,
  "best_1rm_oconner": 109.0,
  "best_1rm_average": 108.5,
  "current_1rm_epley": 105.0,
  "current_1rm_brzycki": 103.0,
  "current_1rm_lander": 102.0,
  "current_1rm_oconner": 104.0,
  "current_1rm_average": 103.5
}
```

### Analytics de Progression
```json
{
  "exercise": "D√©velopp√© couch√©",
  "total_sessions": 15,
  "progression_trend": "Progression",
  "volume_trend_7d": 5.2,
  "volume_trend_30d": 12.8,
  "plateau_detected": false,
  "days_since_last_pr": 7
}
```

## üß™ Tests

### Tests automatis√©s
```bash
# Tests unitaires de l'API
python -m pytest tests/test_api_endpoints.py -v

# Test complet avec l'API en cours d'ex√©cution
python examples/test_api_endpoints.py
```

### Tests manuels avec l'API en cours
```bash
# Test de sant√©
python examples/test_api_endpoints.py http://localhost:8000

# D√©monstration compl√®te
python examples/demo_api_complete.py http://localhost:8000
```

## ‚öôÔ∏è Configuration

### Variables d'environnement
```bash
# Environnement
APP_ENV=development  # development, test, production, docker

# Base de donn√©es de d√©veloppement
DEV_DB_HOST=localhost
DEV_DB_PORT=5432
DEV_DB_NAME=muscle_analytics
DEV_DB_USER=dev
DEV_DB_PASSWORD=devpass
```

### Fichier .env
Le fichier `.env` est automatiquement charg√© au d√©marrage pour configurer la base de donn√©es.

## üîß D√©veloppement

### Structure des services

#### DatabaseService
- Gestion des connexions √† la base de donn√©es
- Requ√™tes pour sessions, sets, exercices
- Gestion des filtres (dates, exercices)

#### AnalyticsService
- Calculs de features avec `FeatureCalculator`
- Conversion des donn√©es en mod√®les Pydantic
- Agr√©gation et formatage des r√©sultats

### Ajout d'un nouvel endpoint

1. **Mod√®le Pydantic** dans `models.py`
```python
class NewModel(BaseModel):
    field1: str
    field2: int
```

2. **Logique m√©tier** dans `services.py`
```python
def get_new_data(self) -> List[NewModel]:
    # Logique de calcul
    return results
```

3. **Endpoint** dans `main.py`
```python
@app.get("/new-endpoint", response_model=List[NewModel])
async def get_new_endpoint(service: AnalyticsService = Depends(get_analytics_service)):
    return service.get_new_data()
```

## üêõ D√©pannage

### Probl√®mes courants

#### Erreur de connexion √† la base
```
DatabaseError: connection to server failed
```
- V√©rifier que PostgreSQL est d√©marr√© : `docker-compose ps`
- V√©rifier la configuration dans `.env`
- Tester la connexion : `python -c "from src.database import get_database; get_database().test_connection()"`

#### Module non trouv√©
```
ModuleNotFoundError: No module named 'src'
```
- Ex√©cuter depuis la racine du projet
- V√©rifier que `PYTHONPATH` inclut le r√©pertoire `src`

#### D√©pendances manquantes
```
ModuleNotFoundError: No module named 'scipy'
```
- Installer les d√©pendances : `pip install -r requirements.txt`
- Ou sp√©cifiquement : `pip install scipy fastapi uvicorn`

### Logs et debugging

#### Logs de l'API
L'API utilise le syst√®me de logging standard de Python. Pour plus de d√©tails :
```bash
python -m uvicorn src.api.main:app --log-level debug
```

#### Validation des donn√©es
FastAPI valide automatiquement les donn√©es avec Pydantic. Les erreurs de validation sont retourn√©es avec des d√©tails pr√©cis.

## üöÄ Prochaines √©tapes

### Phase 3 - Am√©liorations pr√©vues
- [ ] Authentification et autorisation
- [ ] Endpoints pour cr√©er/modifier des donn√©es
- [ ] Cache Redis pour les analytics co√ªteux
- [ ] Rate limiting et monitoring
- [ ] Versioning de l'API (v2)

### Performance
- [ ] Optimisation des requ√™tes SQL
- [ ] Pagination pour les grandes listes
- [ ] Compression des r√©ponses
- [ ] Background tasks pour calculs longs

## üìö Ressources

- **FastAPI Documentation** : https://fastapi.tiangolo.com/
- **Pydantic Models** : https://pydantic.dev/
- **OpenAPI Specification** : https://swagger.io/specification/

---

‚úÖ **Statut Phase 2 - T√¢che 3** : **TERMIN√âE**
- [x] Endpoints API complets pour toutes les donn√©es
- [x] Analytics int√©gr√©es (volume, 1RM, progression)
- [x] Documentation interactive automatique
- [x] Tests unitaires et scripts de validation
- [x] Configuration multi-environnements
